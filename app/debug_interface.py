"""
Interfaz de depuraci√≥n para visualizar chunks y embeddings.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import json
import logging
from typing import Dict, Any, List, Tuple
from sklearn.decomposition import PCA
import umap

from src.retrieval.search_engine import SearchEngine

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Debug - Visualizaci√≥n de Embeddings",
    page_icon="üî¨",
    layout="wide"
)

# Estilos CSS personalizados
st.markdown("""
<style>
    .main {
        padding: 2rem;
    }
    .debug-section {
        background-color: #f8f9fa;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .chunk-viewer {
        font-family: monospace;
        background-color: #f1f3f5;
        padding: 1rem;
        border-radius: 0.3rem;
        white-space: pre-wrap;
    }
    .result-card {
        background-color: #f8f9fa;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
        border-left: 5px solid #0066cc;
    }
    .metadata-tag {
        background-color: #e9ecef;
        padding: 0.2rem 0.5rem;
        border-radius: 0.3rem;
        margin-right: 0.5rem;
        font-size: 0.8rem;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def load_searcher() -> SearchEngine:
    """
    Carga el motor de b√∫squeda (cacheado).
    Usa el √≠ndice FAISS optimizado en lugar de archivos .npy individuales.
    """
    try:
        return SearchEngine(top_k=20)  # Aumentamos para incluir m√°s resultados
    except Exception as e:
        st.error(f"Error cargando SearchEngine: {str(e)}")
        raise

@st.cache_data
def load_embeddings_data() -> Tuple[np.ndarray, List[Dict[str, Any]]]:
    """
    Carga los embeddings y metadatos desde el √≠ndice FAISS optimizado.
    NUEVA VERSI√ìN: Usa el mismo √≠ndice FAISS que SearchEngine para consistencia.
    """
    try:
        # Cargar SearchEngine que tiene el √≠ndice FAISS
        searcher = SearchEngine()
        
        if not hasattr(searcher, 'id_mapping') or not searcher.id_mapping:
            st.error("No se encontr√≥ el √≠ndice FAISS. Por favor, ejecute rebuild_index.py")
            return np.array([]), []
        
        if not hasattr(searcher, 'index') or searcher.index is None:
            st.error("√çndice FAISS no cargado correctamente")
            return np.array([]), []
        
        # Extraer embeddings del √≠ndice FAISS
        total_vectors = searcher.index.ntotal
        if total_vectors == 0:
            st.error("El √≠ndice FAISS est√° vac√≠o")
            return np.array([]), []
        
        # Obtener todos los embeddings del √≠ndice FAISS
        all_embeddings = searcher.index.reconstruct_n(0, total_vectors)
        
        # Crear metadata list en el mismo orden que los embeddings
        all_metadata = []
        for i in range(total_vectors):
            if str(i) in searcher.id_mapping:  # Convertir a string para la clave
                metadata = searcher.id_mapping[str(i)].copy()
                filename = metadata.get('filename', f'chunk_{i}')
                
                all_metadata.append({
                    'filename': filename,
                    'chunk': f"Chunk {i+1}",
                    'metadata': metadata,
                    'text': metadata.get('text', ''),  # Incluir texto si est√° disponible
                    'faiss_id': i
                })
            else:
                # Metadata por defecto para IDs faltantes
                all_metadata.append({
                    'filename': f'unknown_{i}',
                    'chunk': f"Chunk {i+1}",
                    'metadata': {},
                    'text': '',
                    'faiss_id': i
                })
        
        st.success(f"‚úÖ Cargados {total_vectors} embeddings desde √≠ndice FAISS")
        return all_embeddings, all_metadata
        
    except Exception as e:
        st.error(f"Error cargando desde √≠ndice FAISS: {str(e)}")
        st.info("üí° Consejo: Ejecute 'python rebuild_index.py' para reconstruir el √≠ndice")
        return np.array([]), []

@st.cache_data
def reduce_dimensions(embeddings: np.ndarray, method: str = "pca") -> np.ndarray:
    """
    Reduce la dimensionalidad de los embeddings para visualizaci√≥n.
    """
    if len(embeddings) == 0:
        return np.array([])
        
    if method == "pca":
        reducer = PCA(n_components=2)
    else:  # umap
        reducer = umap.UMAP(n_components=2, random_state=42)
    
    return reducer.fit_transform(embeddings)

def plot_embeddings(embeddings_2d: np.ndarray, metadata: List[Dict[str, Any]], color_by: str) -> None:
    """
    Genera un gr√°fico interactivo de embeddings.
    """
    if len(embeddings_2d) == 0:
        st.warning("No hay embeddings para visualizar")
        return
        
    df = pd.DataFrame(
        embeddings_2d,
        columns=['x', 'y']
    )
    
    # A√±adir metadatos
    df['filename'] = [m['filename'] for m in metadata]
    for key in metadata[0]['metadata'].keys():
        df[key] = [m['metadata'][key] for m in metadata]
    
    # Crear gr√°fico
    fig = px.scatter(
        df,
        x='x',
        y='y',
        color=color_by,
        hover_data=['filename'] + list(metadata[0]['metadata'].keys()),
        title=f"Visualizaci√≥n de Embeddings (coloreado por {color_by})"
    )
    
    fig.update_layout(
        showlegend=True,
        width=800,
        height=600
    )
    
    st.plotly_chart(fig)

def render_result_card(result: Dict[str, Any]) -> None:
    """
    Renderiza una tarjeta de resultado con informaci√≥n detallada.
    Ahora usa datos del √≠ndice FAISS que incluye el texto real.
    """
    # Obtener el texto del resultado (ya viene del √≠ndice FAISS)
    chunk_text = result.get('text', '')
    if not chunk_text:
        chunk_text = result.get('metadata', {}).get('text', 'Texto no disponible')
    
    # Truncar texto si es muy largo para la visualizaci√≥n
    if len(chunk_text) > 500:
        chunk_text = chunk_text[:500] + "..."
        
    with st.container():
        st.markdown(f"""
        <div class="result-card">
            <div style="display: flex; justify-content: space-between; align-items: center;">
                <h3 style="margin: 0;">{result['metadata'].get('filename', 'Desconocido')}</h3>
                <span class="score-badge">Score: {result['score']:.2f}</span>
            </div>
            <div style="margin: 0.5rem 0;">
                {' '.join([f'<span class="metadata-tag">{k}: {v}</span>' 
                          for k, v in result['metadata'].items() if v])}
            </div>
            <div class="chunk-viewer" style="margin: 1rem 0;">
                {chunk_text}
            </div>
        </div>
        """, unsafe_allow_html=True)

def main():
    """Funci√≥n principal de la interfaz de depuraci√≥n"""
    
    st.title("üî¨ Debug - Visualizaci√≥n de Embeddings")
    
    try:
        # Inicializar componentes
        searcher = load_searcher()
        embeddings, metadata = load_embeddings_data()
        logger = logging.getLogger("debug_interface")
        
        if len(embeddings) == 0:
            st.error("No se encontraron embeddings para visualizar.")
            st.info("üí° Posibles soluciones:")
            st.code("python -c \"import sys; sys.path.append('src'); from embeddings.embed_documents import DocumentEmbedder; embedder = DocumentEmbedder(); embedder.process_documents()\"")
            st.code("python rebuild_index.py")
            return
            
    except Exception as e:
        st.error(f"Error inicializando la aplicaci√≥n: {str(e)}")
        st.info("üí° Intente reiniciar la aplicaci√≥n o reconstruir el √≠ndice FAISS")
        return
    
    # Informaci√≥n del sistema (NUEVA)
    st.sidebar.markdown("### üîß Estado del Sistema")
    st.sidebar.metric("Total de chunks", len(embeddings))
    st.sidebar.metric("Fuente de datos", "√çndice FAISS")
    
    # Contar documentos de moto
    moto_count = len([m for m in metadata if 'moto' in m['filename'].lower() or 'ciclomotor' in m['filename'].lower()])
    st.sidebar.metric("Documentos de moto", moto_count)
    
    if hasattr(searcher, 'index') and searcher.index:
        st.sidebar.success("‚úÖ √çndice FAISS cargado")
        st.sidebar.metric("Vectores en FAISS", searcher.index.ntotal)
    else:
        st.sidebar.error("‚ùå √çndice FAISS no cargado")
    
    # Tabs para diferentes funcionalidades
    tab1, tab2, tab3 = st.tabs([
        "üìä Visualizaci√≥n de Embeddings",
        "üìù Explorador de Chunks",
        "üîç Pruebas de B√∫squeda"
    ])
    
    # Tab 1: Visualizaci√≥n de Embeddings
    with tab1:
        st.markdown("### Visualizaci√≥n de Embeddings")
        
        col1, col2 = st.columns(2)
        
        with col1:
            reduction_method = st.selectbox(
                "M√©todo de reducci√≥n de dimensionalidad",
                ["PCA", "UMAP"],
                key="reduction_method"
            )
        
        with col2:
            color_by = st.selectbox(
                "Colorear por",
                ["filename"] + list(metadata[0]['metadata'].keys()),
                key="color_by"
            )
        
        # Reducir dimensionalidad y visualizar
        embeddings_2d = reduce_dimensions(
            embeddings,
            method=reduction_method.lower()
        )
        
        plot_embeddings(embeddings_2d, metadata, color_by)
        
        # M√©tricas de embeddings
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "Total de embeddings",
                embeddings.shape[0]
            )
        
        with col2:
            st.metric(
                "Dimensi√≥n original",
                embeddings.shape[1]
            )
        
        with col3:
            st.metric(
                "Documentos √∫nicos",
                len(set(m['filename'] for m in metadata))
            )
    
    # Tab 2: Explorador de Chunks
    with tab2:
        st.markdown("### Explorador de Chunks")
        
        # Filtros
        col1, col2 = st.columns(2)
        
        with col1:
            selected_file = st.selectbox(
                "Seleccionar documento",
                sorted(set(m['filename'] for m in metadata))
            )
        
        # Mostrar chunks del documento seleccionado
        doc_chunks = [
            (i, m) for i, m in enumerate(metadata)
            if m['filename'] == selected_file
        ]
        
        if doc_chunks:
            st.success(f"Encontrados {len(doc_chunks)} chunks para {selected_file}")
            
            for i, chunk_data in doc_chunks:
                chunk_text = chunk_data.get('text', 'Texto no disponible')
                if not chunk_text:
                    chunk_text = f"Chunk {i + 1} - Contenido no disponible"
                
                with st.expander(f"Chunk {i + 1} (ID FAISS: {chunk_data.get('faiss_id', i)})"):
                    st.markdown(f"""
                    <div class="chunk-viewer">
                    {chunk_text[:1000]}{'...' if len(chunk_text) > 1000 else ''}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Mostrar metadatos del chunk
                    if chunk_data.get('metadata'):
                        st.json(chunk_data['metadata'])
                    else:
                        st.info("Metadatos no disponibles para este chunk")
        else:
            st.warning(f"No se encontraron chunks para {selected_file}")
    
    # Tab 3: Pruebas de B√∫squeda
    with tab3:
        st.markdown("### Pruebas de B√∫squeda")
        
        # Consulta de prueba
        query = st.text_input(
            "Consulta de prueba",
            placeholder="Escribe una consulta para probar la b√∫squeda"
        )
        
        # Filtros de b√∫squeda
        with st.expander("Filtros de b√∫squeda"):
            col1, col2 = st.columns(2)
            
            filter_params = {}
            # Crear un conjunto de claves √∫nicas de metadatos
            unique_metadata_keys = sorted(set(
                k for m in metadata 
                for k in m['metadata'].keys() 
                if m['metadata'].get(k) is not None
            ))
            
            for i, key in enumerate(unique_metadata_keys):
                with col1 if i % 2 == 0 else col2:
                    # Obtener todos los valores √∫nicos para esta clave
                    unique_values = sorted(set(
                        str(m['metadata'].get(key)) 
                        for m in metadata 
                        if m['metadata'].get(key) is not None
                    ))
                    selected = st.multiselect(
                        f"Filtrar por {key}",
                        options=unique_values,
                        key=f"filter_{key}_{i}"  # Hacemos la clave √∫nica a√±adiendo el √≠ndice
                    )
                    if selected:
                        filter_params[key] = selected
        
        if st.button("Buscar", type="primary"):
            if query:
                try:
                    # Realizar b√∫squeda usando el mismo motor que los tests exitosos
                    # El par√°metro filters no est√° implementado en SearchEngine.search()
                    results = searcher.search(query=query)
                    
                    # Mostrar estad√≠sticas
                    st.markdown(f"#### üìÑ Resultados ({len(results)})")
                    
                    # Contar documentos de moto en resultados
                    moto_results = 0
                    for result in results:
                        filename = result['metadata'].get('filename', '')
                        if 'moto' in filename.lower() or 'ciclomotor' in filename.lower():
                            moto_results += 1
                    
                    if moto_results > 0:
                        st.success(f"üèçÔ∏è {moto_results} documentos de moto encontrados!")
                    else:
                        st.warning("‚ùå No se encontraron documentos de moto en los resultados")
                    
                    # Agrupar resultados por documento
                    grouped_results = {}
                    for result in results:
                        filename = result['metadata'].get('filename', 'Desconocido')
                        if filename not in grouped_results:
                            grouped_results[filename] = []
                        grouped_results[filename].append(result)
                    
                    # Mostrar resultados agrupados
                    for filename, doc_results in grouped_results.items():
                        # Destacar documentos de moto
                        is_moto = 'moto' in filename.lower() or 'ciclomotor' in filename.lower()
                        icon = "üèçÔ∏è" if is_moto else "üìÑ"
                        
                        with st.expander(f"{icon} {filename} ({len(doc_results)} chunks)"):
                            for result in doc_results:
                                render_result_card(result)
                    
                    # Visualizar embedding de la consulta junto con los resultados
                    st.markdown("#### üìä Visualizaci√≥n de la consulta")
                    
                    try:
                        # Generar embedding de la consulta
                        query_embedding_2d = searcher.process_query(query)
                        
                        # Convertir de 2D a 1D para la visualizaci√≥n
                        if query_embedding_2d.ndim > 1:
                            query_embedding = query_embedding_2d.flatten()
                        else:
                            query_embedding = query_embedding_2d
                        
                        # Verificar que las dimensiones coincidan
                        if query_embedding.shape[0] != embeddings.shape[1]:
                            st.warning(f"Dimensiones no coinciden: query={query_embedding.shape[0]}, embeddings={embeddings.shape[1]}")
                        else:
                            # Combinar embeddings
                            combined_embeddings = np.vstack([
                                embeddings,
                                query_embedding.reshape(1, -1)
                            ])
                            
                            # Reducir dimensionalidad
                            combined_2d = reduce_dimensions(combined_embeddings)
                            
                            # Crear gr√°fico
                            fig = go.Figure()
                            
                            # Plotear embeddings existentes
                            fig.add_trace(go.Scatter(
                                x=combined_2d[:-1, 0],
                                y=combined_2d[:-1, 1],
                                mode='markers',
                                name='Documentos',
                                marker=dict(
                                    color='blue',
                                    size=8,
                                    opacity=0.5
                                ),
                                hovertemplate='Documento: %{text}<extra></extra>',
                                text=[m['filename'] for m in metadata]
                            ))
                            
                            # Plotear consulta
                            fig.add_trace(go.Scatter(
                                x=[combined_2d[-1, 0]],
                                y=[combined_2d[-1, 1]],
                                mode='markers',
                                name='Consulta',
                                marker=dict(
                                    color='red',
                                    size=15,
                                    symbol='star'
                                ),
                                hovertemplate=f'Consulta: {query}<extra></extra>'
                            ))
                            
                            fig.update_layout(
                                title="Visualizaci√≥n de la consulta en el espacio de embeddings",
                                showlegend=True,
                                width=800,
                                height=600
                            )
                            
                            st.plotly_chart(fig)
                    
                    except Exception as e:
                        st.error(f"Error en visualizaci√≥n: {str(e)}")
                        st.info("La visualizaci√≥n de la consulta no est√° disponible en este momento.")
                    
                except Exception as e:
                    st.error(f"Error al realizar la b√∫squeda: {str(e)}")
            else:
                st.warning("Por favor, ingresa una consulta para buscar.")

if __name__ == "__main__":
    main() 