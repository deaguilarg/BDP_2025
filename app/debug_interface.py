"""
Interfaz de depuraci칩n para visualizar chunks y embeddings.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import json
from typing import Dict, Any, List, Tuple
from sklearn.decomposition import PCA
import umap

from src.retrieval.search_engine import SearchEngine
from src.monitoring.logger import RAGLogger

# Configuraci칩n de la p치gina
st.set_page_config(
    page_title="Debug - Visualizaci칩n de Embeddings",
    page_icon="游댧",
    layout="wide"
)

# Estilos CSS personalizados
st.markdown("""
<style>
    .main {
        padding: 2rem;
    }
    .debug-section {
        background-color: #f8f9fa;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .chunk-viewer {
        font-family: monospace;
        background-color: #f1f3f5;
        padding: 1rem;
        border-radius: 0.3rem;
        white-space: pre-wrap;
    }
    .result-card {
        background-color: #f8f9fa;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
        border-left: 5px solid #0066cc;
    }
    .metadata-tag {
        background-color: #e9ecef;
        padding: 0.2rem 0.5rem;
        border-radius: 0.3rem;
        margin-right: 0.5rem;
        font-size: 0.8rem;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def load_searcher() -> SearchEngine:
    """
    Carga el motor de b칰squeda (cacheado).
    """
    return SearchEngine(top_k=10)  # Aumentamos el n칰mero de resultados

@st.cache_data
def load_embeddings_data() -> Tuple[np.ndarray, List[Dict[str, Any]]]:
    """
    Carga los embeddings y metadatos (cacheado).
    """
    embeddings_dir = Path("data/embeddings")
    if not embeddings_dir.exists():
        st.error("No se encontr칩 el directorio de embeddings")
        return np.array([]), []
    
    all_embeddings = []
    all_metadata = []
    
    # Cargar metadatos generales
    metadata_path = Path("models/processed_documents.json")
    if not metadata_path.exists():
        st.error("No se encontr칩 el archivo de metadatos")
        return np.array([]), []
    
    with open(metadata_path, 'r', encoding='utf-8') as f:
        documents_metadata = json.load(f)
    
    # Crear diccionario de metadatos por filename
    metadata_dict = {doc['filename']: doc['metadata'] for doc in documents_metadata}
    
    # Cargar embeddings y metadatos individuales
    for npy_file in embeddings_dir.glob("*.npy"):
        try:
            # Cargar embeddings
            embeddings = np.load(npy_file)
            
            # Verificar que embeddings sea un array numpy
            if not isinstance(embeddings, np.ndarray):
                st.warning(f"El archivo {npy_file.name} no contiene un array numpy v치lido")
                continue
                
            # Asegurarnos de que embeddings tenga la forma correcta
            if len(embeddings.shape) == 1:
                embeddings = embeddings.reshape(1, -1)
            
            # Cargar metadatos correspondientes
            metadata_file = npy_file.with_suffix('.json')
            if metadata_file.exists():
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    doc_metadata = json.load(f)
                
                # Manejar tanto listas como diccionarios en el JSON
                if isinstance(doc_metadata, list):
                    # Si es una lista, asumimos que cada elemento tiene su propio texto y metadatos
                    for i, chunk_data in enumerate(doc_metadata):
                        if i >= len(embeddings):
                            break
                            
                        chunk_metadata = chunk_data.get('metadata', {})
                        if not isinstance(chunk_metadata, dict):
                            chunk_metadata = {}
                            
                        # Obtener metadatos generales
                        filename = npy_file.stem
                        general_metadata = metadata_dict.get(filename, {})
                        
                        # Combinar metadatos
                        combined_metadata = {**general_metadata, **chunk_metadata}
                        
                        all_embeddings.append(embeddings[i])
                        all_metadata.append({
                            'filename': filename,
                            'chunk': f"Chunk {i+1}",
                            'metadata': combined_metadata
                        })
                elif isinstance(doc_metadata, dict):
                    # Si es un diccionario, usamos el formato anterior
                    filename = doc_metadata.get('filename', npy_file.stem)
                    general_metadata = metadata_dict.get(filename, {})
                    doc_metadata_dict = doc_metadata.get('metadata', {})
                    if not isinstance(doc_metadata_dict, dict):
                        doc_metadata_dict = {}
                    
                    combined_metadata = {**general_metadata, **doc_metadata_dict}
                    
                    for i in range(len(embeddings)):
                        all_embeddings.append(embeddings[i])
                        all_metadata.append({
                            'filename': filename,
                            'chunk': f"Chunk {i+1}",
                            'metadata': combined_metadata
                        })
                else:
                    st.warning(f"El archivo {metadata_file.name} no tiene un formato JSON v치lido")
                    continue
                
        except Exception as e:
            st.warning(f"Error cargando {npy_file.name}: {str(e)}")
            continue
    
    if not all_embeddings:
        st.error("No se encontraron embeddings para visualizar")
        return np.array([]), []
    
    return np.array(all_embeddings), all_metadata

@st.cache_data
def reduce_dimensions(embeddings: np.ndarray, method: str = "pca") -> np.ndarray:
    """
    Reduce la dimensionalidad de los embeddings para visualizaci칩n.
    """
    if len(embeddings) == 0:
        return np.array([])
        
    if method == "pca":
        reducer = PCA(n_components=2)
    else:  # umap
        reducer = umap.UMAP(n_components=2, random_state=42)
    
    return reducer.fit_transform(embeddings)

def plot_embeddings(embeddings_2d: np.ndarray, metadata: List[Dict[str, Any]], color_by: str) -> None:
    """
    Genera un gr치fico interactivo de embeddings.
    """
    if len(embeddings_2d) == 0:
        st.warning("No hay embeddings para visualizar")
        return
        
    df = pd.DataFrame(
        embeddings_2d,
        columns=['x', 'y']
    )
    
    # A침adir metadatos
    df['filename'] = [m['filename'] for m in metadata]
    for key in metadata[0]['metadata'].keys():
        df[key] = [m['metadata'][key] for m in metadata]
    
    # Crear gr치fico
    fig = px.scatter(
        df,
        x='x',
        y='y',
        color=color_by,
        hover_data=['filename'] + list(metadata[0]['metadata'].keys()),
        title=f"Visualizaci칩n de Embeddings (coloreado por {color_by})"
    )
    
    fig.update_layout(
        showlegend=True,
        width=800,
        height=600
    )
    
    st.plotly_chart(fig)

def render_result_card(result: Dict[str, Any]) -> None:
    """
    Renderiza una tarjeta de resultado con informaci칩n detallada.
    """
    # Intentar obtener el texto del chunk
    chunk_text = result.get('text', '')
    if not chunk_text:
        chunk_text = result.get('metadata', {}).get('text', '')
    with st.container():
        st.markdown(f"""
        <div class="result-card">
            <div style="display: flex; justify-content: space-between; align-items: center;">
                <h3 style="margin: 0;">{result['metadata'].get('filename', 'Desconocido')}</h3>
                <span class="score-badge">Score: {result['score']:.2f}</span>
            </div>
            <div style="margin: 0.5rem 0;">
                {' '.join([f'<span class="metadata-tag">{k}: {v}</span>' 
                          for k, v in result['metadata'].items() if v])}
            </div>
            <div class="chunk-viewer" style="margin: 1rem 0;">
                {chunk_text}
            </div>
        </div>
        """, unsafe_allow_html=True)

def main():
    """Funci칩n principal de la interfaz de depuraci칩n"""
    
    st.title("游댧 Debug - Visualizaci칩n de Embeddings")
    
    # Inicializar componentes
    searcher = load_searcher()
    embeddings, metadata = load_embeddings_data()
    logger = RAGLogger()
    
    if len(embeddings) == 0:
        st.error("No se encontraron embeddings para visualizar. Por favor, ejecute primero el generador de embeddings.")
        return
    
    # Tabs para diferentes funcionalidades
    tab1, tab2, tab3 = st.tabs([
        "游늵 Visualizaci칩n de Embeddings",
        "游닇 Explorador de Chunks",
        "游댌 Pruebas de B칰squeda"
    ])
    
    # Tab 1: Visualizaci칩n de Embeddings
    with tab1:
        st.markdown("### Visualizaci칩n de Embeddings")
        
        col1, col2 = st.columns(2)
        
        with col1:
            reduction_method = st.selectbox(
                "M칠todo de reducci칩n de dimensionalidad",
                ["PCA", "UMAP"],
                key="reduction_method"
            )
        
        with col2:
            color_by = st.selectbox(
                "Colorear por",
                ["filename"] + list(metadata[0]['metadata'].keys()),
                key="color_by"
            )
        
        # Reducir dimensionalidad y visualizar
        embeddings_2d = reduce_dimensions(
            embeddings,
            method=reduction_method.lower()
        )
        
        plot_embeddings(embeddings_2d, metadata, color_by)
        
        # M칠tricas de embeddings
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "Total de embeddings",
                embeddings.shape[0]
            )
        
        with col2:
            st.metric(
                "Dimensi칩n original",
                embeddings.shape[1]
            )
        
        with col3:
            st.metric(
                "Documentos 칰nicos",
                len(set(m['filename'] for m in metadata))
            )
    
    # Tab 2: Explorador de Chunks
    with tab2:
        st.markdown("### Explorador de Chunks")
        
        # Filtros
        col1, col2 = st.columns(2)
        
        with col1:
            selected_file = st.selectbox(
                "Seleccionar documento",
                sorted(set(m['filename'] for m in metadata))
            )
        
        # Mostrar chunks del documento seleccionado
        doc_chunks = [
            (i, m['chunk']) for i, m in enumerate(metadata)
            if m['filename'] == selected_file
        ]
        
        for i, chunk in doc_chunks:
            with st.expander(f"Chunk {i + 1}"):
                st.markdown(f"""
                <div class="chunk-viewer">
                {chunk}
                </div>
                """, unsafe_allow_html=True)
                
                # Mostrar metadatos del chunk
                st.json(metadata[i]['metadata'])
    
    # Tab 3: Pruebas de B칰squeda
    with tab3:
        st.markdown("### Pruebas de B칰squeda")
        
        # Consulta de prueba
        query = st.text_input(
            "Consulta de prueba",
            placeholder="Escribe una consulta para probar la b칰squeda"
        )
        
        # Filtros de b칰squeda
        with st.expander("Filtros de b칰squeda"):
            col1, col2 = st.columns(2)
            
            filter_params = {}
            # Crear un conjunto de claves 칰nicas de metadatos
            unique_metadata_keys = sorted(set(
                k for m in metadata 
                for k in m['metadata'].keys() 
                if m['metadata'].get(k) is not None
            ))
            
            for i, key in enumerate(unique_metadata_keys):
                with col1 if i % 2 == 0 else col2:
                    # Obtener todos los valores 칰nicos para esta clave
                    unique_values = sorted(set(
                        str(m['metadata'].get(key)) 
                        for m in metadata 
                        if m['metadata'].get(key) is not None
                    ))
                    selected = st.multiselect(
                        f"Filtrar por {key}",
                        options=unique_values,
                        key=f"filter_{key}_{i}"  # Hacemos la clave 칰nica a침adiendo el 칤ndice
                    )
                    if selected:
                        filter_params[key] = selected
        
        if st.button("Buscar", type="primary"):
            if query:
                try:
                    # Realizar b칰squeda
                    results = searcher.search(query, filters=filter_params if filter_params else None)
                    
                    # Mostrar resultados
                    st.markdown(f"#### 游늯 Resultados ({len(results)})")
                    
                    # Agrupar resultados por documento
                    grouped_results = {}
                    for result in results:
                        filename = result['metadata'].get('filename', 'Desconocido')
                        if filename not in grouped_results:
                            grouped_results[filename] = []
                        grouped_results[filename].append(result)
                    
                    # Mostrar resultados agrupados
                    for filename, doc_results in grouped_results.items():
                        with st.expander(f"游늯 {filename} ({len(doc_results)} chunks)"):
                            for result in doc_results:
                                render_result_card(result)
                    
                    # Visualizar embedding de la consulta junto con los resultados
                    st.markdown("#### 游늵 Visualizaci칩n de la consulta")
                    
                    # Generar embedding de la consulta
                    query_embedding = searcher.process_query(query)
                    
                    # Combinar embeddings
                    combined_embeddings = np.vstack([
                        embeddings,
                        query_embedding
                    ])
                    
                    # Reducir dimensionalidad
                    combined_2d = reduce_dimensions(combined_embeddings)
                    
                    # Crear gr치fico
                    fig = go.Figure()
                    
                    # Plotear embeddings existentes
                    fig.add_trace(go.Scatter(
                        x=combined_2d[:-1, 0],
                        y=combined_2d[:-1, 1],
                        mode='markers',
                        name='Documentos',
                        marker=dict(
                            color='blue',
                            size=8,
                            opacity=0.5
                        )
                    ))
                    
                    # Plotear consulta
                    fig.add_trace(go.Scatter(
                        x=[combined_2d[-1, 0]],
                        y=[combined_2d[-1, 1]],
                        mode='markers',
                        name='Consulta',
                        marker=dict(
                            color='red',
                            size=12,
                            symbol='star'
                        )
                    ))
                    
                    fig.update_layout(
                        title="Visualizaci칩n de la consulta en el espacio de embeddings",
                        showlegend=True,
                        width=800,
                        height=600
                    )
                    
                    st.plotly_chart(fig)
                    
                except Exception as e:
                    st.error(f"Error al realizar la b칰squeda: {str(e)}")
            else:
                st.warning("Por favor, ingresa una consulta para buscar.")

if __name__ == "__main__":
    main() 